<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Meet Voice Bot Bridge</title>
    <style>
      :root {
        --bg: #0f172a;
        --surface: #1e293b;
        --text: #e2e8f0;
        --muted: #94a3b8;
        --ok: #16a34a;
        --warn: #ea580c;
      }
      body {
        margin: 0;
        font-family: "IBM Plex Sans", "Segoe UI", sans-serif;
        background: radial-gradient(circle at top right, #1d4ed8, var(--bg) 45%);
        color: var(--text);
      }
      .panel {
        max-width: 900px;
        margin: 24px auto;
        padding: 20px;
        background: color-mix(in srgb, var(--surface) 88%, black);
        border: 1px solid #334155;
        border-radius: 12px;
      }
      h1 {
        margin: 0 0 12px;
        font-size: 22px;
      }
      .status {
        margin: 0 0 16px;
        color: var(--muted);
      }
      .status strong {
        color: var(--ok);
      }
      .status strong.warn {
        color: var(--warn);
      }
      #log {
        margin: 0;
        padding: 12px;
        white-space: pre-wrap;
        font: 13px/1.4 ui-monospace, SFMono-Regular, Menlo, monospace;
        background: #020617;
        border-radius: 8px;
        min-height: 220px;
      }
    </style>
  </head>
  <body>
    <main class="panel">
      <h1>Meet Voice Bot Bridge</h1>
      <p class="status">
        Recognition:
        <strong id="recognitionState">starting...</strong>
      </p>
      <p class="status">
        Speech synthesis:
        <strong id="speechState">idle</strong>
      </p>
      <pre id="log"></pre>
    </main>

    <script>
      (() => {
        const VOICE_CORE_PROTOCOL = "voice.core.v1";
        const VOICE_CORE_VERSION = 1;
        const VOICE_BINARY_HEADER_BYTES = 16;
        const VOICE_AUDIO_KIND_INPUT = 1;
        const VOICE_AUDIO_KIND_OUTPUT = 2;
        const VOICE_AUDIO_CODEC_PCM16 = 1;
        const LOOPBACK_INPUT_REGEX =
          /(blackhole|loopback|soundflower|vb-?cable|cable output|monitor of|virtual|aggregate)/i;

        const state = {
          language: "en-US",
          silenceMs: 180,
          audioUnlocked: false,
          captureGateUntilMs: 0,
          speaking: false,
          ttsDuckLevel: 0.22,
          ttsDuckActive: false,
          ttsOutputDeviceId: "",
          ttsOutputDeviceLabel: "",
          ttsOutputConfigured: false,
          ttsOutputSupportLogged: false,
          currentAudioElement: null,
          playback: {
            current: null,
            queue: [],
            queueDurationMs: 0,
            playedMs: 0,
            waiters: [],
            loopPromise: null,
            bufferChunks: [],
            bufferBytes: 0,
            bufferTimer: null,
            bufferSampleRate: 24000,
            bufferChannels: 1
          },
          core: {
            active: false,
            starting: false,
            ws: null,
            sessionId: "",
            inputSeq: 0,
            localStream: null,
            audioContext: null,
            sourceNode: null,
            processorNode: null,
            sinkNode: null,
            sampleRate: 48000,
            speechActive: false,
            speechStartedAtMs: 0,
            lastSpeechAtMs: 0,
            pendingInput: false,
            bargeInMinMs: 220,
            lastAudioChunkLogAtMs: 0
          }
        };

        let unlockAudioContext = null;

        const recognitionStateEl = document.getElementById("recognitionState");
        const speechStateEl = document.getElementById("speechState");
        const logEl = document.getElementById("log");

        function setRecognitionState(text, warning = false) {
          recognitionStateEl.textContent = text;
          recognitionStateEl.className = warning ? "warn" : "";
        }

        function setSpeechState(text, warning = false) {
          speechStateEl.textContent = text;
          speechStateEl.className = warning ? "warn" : "";
        }

        function addLog(message) {
          const ts = new Date().toISOString();
          const line = `[${ts}] ${message}`;
          logEl.textContent = `${line}\n${logEl.textContent}`.slice(0, 14000);
          if (typeof window.notifyBridgeLog === "function") {
            Promise.resolve(window.notifyBridgeLog(message)).catch(() => {});
          }
        }

        function emitBridgeEvent(payload = {}) {
          if (!payload || typeof payload !== "object") {
            return;
          }
          if (typeof window.notifyBridgeEvent !== "function") {
            return;
          }
          Promise.resolve(
            window.notifyBridgeEvent({
              ts: Date.now(),
              ...payload
            })
          ).catch(() => {});
        }

        function effectiveTtsVolume() {
          if (!state.ttsDuckActive) {
            return 1;
          }
          const duck = Number(state.ttsDuckLevel);
          if (!Number.isFinite(duck)) {
            return 0.22;
          }
          return Math.max(0, Math.min(1, duck));
        }

        function applyCurrentAudioVolume() {
          const volume = effectiveTtsVolume();
          const audio = state.currentAudioElement;
          if (!audio) {
            return;
          }
          try {
            audio.volume = volume;
          } catch (_) {
            // Ignore runtime volume update failures.
          }
        }

        function parseQuery() {
          const params = new URLSearchParams(window.location.search);
          state.language = params.get("lang") || state.language;
          state.silenceMs = Number(params.get("silenceMs")) || state.silenceMs;

          const duckLevel = Number(params.get("ttsDuckLevel"));
          if (Number.isFinite(duckLevel)) {
            state.ttsDuckLevel = Math.max(0, Math.min(1, duckLevel));
          }

          state.ttsOutputDeviceId =
            (params.get("ttsOutputDeviceId") || state.ttsOutputDeviceId || "").trim();
          state.ttsOutputDeviceLabel =
            (params.get("ttsOutputDeviceLabel") || state.ttsOutputDeviceLabel || "").trim();
        }

        function bytesToBase64(bytes) {
          let binary = "";
          const chunkSize = 0x8000;
          for (let index = 0; index < bytes.length; index += chunkSize) {
            const slice = bytes.subarray(index, index + chunkSize);
            binary += String.fromCharCode(...slice);
          }
          return btoa(binary);
        }

        function base64ToBytes(base64) {
          const binary = atob(String(base64 || ""));
          const bytes = new Uint8Array(binary.length);
          for (let index = 0; index < binary.length; index += 1) {
            bytes[index] = binary.charCodeAt(index);
          }
          return bytes;
        }

        function downsampleFloat32Buffer(input, inputSampleRate, targetSampleRate) {
          if (!(input instanceof Float32Array) || input.length === 0) {
            return new Float32Array(0);
          }

          const inRate = Number(inputSampleRate) || 0;
          const outRate = Number(targetSampleRate) || 0;
          if (!inRate || !outRate || inRate <= outRate) {
            return input;
          }

          const ratio = inRate / outRate;
          const outputLength = Math.max(1, Math.round(input.length / ratio));
          const output = new Float32Array(outputLength);

          let inputOffset = 0;
          for (let outputOffset = 0; outputOffset < outputLength; outputOffset += 1) {
            const nextInputOffset = Math.min(
              input.length,
              Math.round((outputOffset + 1) * ratio)
            );

            let sum = 0;
            let count = 0;
            for (let index = inputOffset; index < nextInputOffset; index += 1) {
              sum += input[index];
              count += 1;
            }
            output[outputOffset] = count > 0 ? sum / count : 0;
            inputOffset = nextInputOffset;
          }

          return output;
        }

        function float32ToPcm16Bytes(input) {
          const source = input instanceof Float32Array ? input : new Float32Array(0);
          const bytes = new Uint8Array(source.length * 2);
          const view = new DataView(bytes.buffer);

          for (let index = 0; index < source.length; index += 1) {
            const sample = Math.max(-1, Math.min(1, source[index]));
            const scaled = sample < 0 ? sample * 0x8000 : sample * 0x7fff;
            view.setInt16(index * 2, Math.round(scaled), true);
          }

          return bytes;
        }

        function computePeak(samples) {
          if (!(samples instanceof Float32Array) || samples.length === 0) {
            return 0;
          }
          let peak = 0;
          for (let index = 0; index < samples.length; index += 1) {
            const abs = Math.abs(samples[index]);
            if (abs > peak) {
              peak = abs;
            }
          }
          return peak;
        }

        function encodeVoiceInputBinaryAudioFrame({
          seq = 0,
          sampleRateHz = 24000,
          channels = 1,
          pcmBytes
        } = {}) {
          const bytes =
            pcmBytes instanceof Uint8Array
              ? pcmBytes
              : pcmBytes instanceof ArrayBuffer
                ? new Uint8Array(pcmBytes)
                : new Uint8Array(0);
          if (!bytes.byteLength) {
            return null;
          }

          const header = new ArrayBuffer(VOICE_BINARY_HEADER_BYTES);
          const view = new DataView(header);
          view.setUint8(0, VOICE_CORE_VERSION);
          view.setUint8(1, VOICE_AUDIO_KIND_INPUT);
          view.setUint16(2, VOICE_AUDIO_CODEC_PCM16, false);
          view.setUint32(4, Number(seq) >>> 0, false);
          view.setUint32(
            8,
            Math.max(1, Math.trunc(Number(sampleRateHz) || 24000)) >>> 0,
            false
          );
          view.setUint8(12, Math.max(1, Math.min(2, Math.trunc(Number(channels) || 1))));
          view.setUint8(13, 0);
          view.setUint16(14, 0, false);

          const binary = new Uint8Array(VOICE_BINARY_HEADER_BYTES + bytes.byteLength);
          binary.set(new Uint8Array(header), 0);
          binary.set(bytes, VOICE_BINARY_HEADER_BYTES);
          return binary.buffer;
        }

        function decodeVoiceBinaryAudioFrame(data) {
          const bytes =
            data instanceof Uint8Array
              ? data
              : data instanceof ArrayBuffer
                ? new Uint8Array(data)
                : new Uint8Array(0);
          if (bytes.byteLength < VOICE_BINARY_HEADER_BYTES) {
            throw new Error("Binary frame is too short.");
          }

          const view = new DataView(bytes.buffer, bytes.byteOffset, bytes.byteLength);
          const version = view.getUint8(0);
          if (version !== VOICE_CORE_VERSION) {
            throw new Error(`Unsupported binary frame version: ${version}.`);
          }

          const kindCode = view.getUint8(1);
          const codecCode = view.getUint16(2, false);
          const seq = view.getUint32(4, false);
          const sampleRateHz = view.getUint32(8, false);
          const channels = view.getUint8(12);

          if (codecCode !== VOICE_AUDIO_CODEC_PCM16) {
            throw new Error(`Unsupported audio codec code: ${codecCode}.`);
          }

          return {
            kindCode,
            seq,
            sampleRateHz: Math.max(8000, Number(sampleRateHz) || 24000),
            channels: Math.max(1, Number(channels) || 1),
            bytes: bytes.subarray(VOICE_BINARY_HEADER_BYTES)
          };
        }

        function pcm16BytesToWavBase64(bytes, sampleRate = 24000, channels = 1) {
          const safeBytes =
            bytes instanceof Uint8Array
              ? bytes
              : bytes instanceof ArrayBuffer
                ? new Uint8Array(bytes)
                : new Uint8Array(0);
          if (!safeBytes.byteLength) {
            return "";
          }

          const dataByteLength = safeBytes.byteLength;
          const header = new ArrayBuffer(44);
          const view = new DataView(header);
          const safeSampleRate = Math.max(8000, Math.trunc(Number(sampleRate) || 24000));
          const safeChannels = Math.max(1, Math.min(2, Math.trunc(Number(channels) || 1)));
          const blockAlign = safeChannels * 2;
          const byteRate = safeSampleRate * blockAlign;

          const writeAscii = (offset, value) => {
            for (let index = 0; index < value.length; index += 1) {
              view.setUint8(offset + index, value.charCodeAt(index));
            }
          };

          writeAscii(0, "RIFF");
          view.setUint32(4, 36 + dataByteLength, true);
          writeAscii(8, "WAVE");
          writeAscii(12, "fmt ");
          view.setUint32(16, 16, true);
          view.setUint16(20, 1, true);
          view.setUint16(22, safeChannels, true);
          view.setUint32(24, safeSampleRate, true);
          view.setUint32(28, byteRate, true);
          view.setUint16(32, blockAlign, true);
          view.setUint16(34, 16, true);
          writeAscii(36, "data");
          view.setUint32(40, dataByteLength, true);

          const wavBytes = new Uint8Array(44 + dataByteLength);
          wavBytes.set(new Uint8Array(header), 0);
          wavBytes.set(safeBytes, 44);

          return bytesToBase64(wavBytes);
        }

        function normalizeLanguageTag(value) {
          const normalized = String(value || "").trim().toLowerCase();
          if (!normalized) {
            return "";
          }
          const [primary] = normalized.split("-");
          if (!primary || primary.length < 2 || primary.length > 3) {
            return "";
          }
          return primary;
        }

        function createVoiceCoreMsgId(prefix = "bridge") {
          return `${prefix}_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
        }

        function buildVoiceCoreEnvelope({ type, payload = {}, sessionId = "", replyTo = null } = {}) {
          return {
            v: VOICE_CORE_VERSION,
            type: String(type || "").trim().toLowerCase(),
            msg_id: createVoiceCoreMsgId("bridge"),
            session_id: String(sessionId || "").trim() || undefined,
            reply_to: String(replyTo || "").trim() || undefined,
            ts_ms: Date.now(),
            payload: payload && typeof payload === "object" ? payload : {}
          };
        }

        function formatDeviceLabel(device, index) {
          const label = String(device?.label || "").trim() || `audioinput#${index + 1}`;
          const id = String(device?.deviceId || "").trim() || "unknown";
          return `${label} [${id}]`;
        }

        async function listAudioInputDevices() {
          try {
            const devices = await navigator.mediaDevices.enumerateDevices();
            return devices.filter((device) => device.kind === "audioinput");
          } catch (_) {
            return [];
          }
        }

        async function listAudioOutputDevices() {
          try {
            const devices = await navigator.mediaDevices.enumerateDevices();
            return devices.filter((device) => device.kind === "audiooutput");
          } catch (_) {
            return [];
          }
        }

        function findDeviceByLabel(devices, requestedLabel) {
          if (!requestedLabel) {
            return null;
          }
          const needle = requestedLabel.toLowerCase().trim();
          if (!needle) {
            return null;
          }
          return (
            devices.find((device) =>
              String(device.label || "")
                .toLowerCase()
                .includes(needle)
            ) || null
          );
        }

        function findLoopbackDevice(devices) {
          return (
            devices.find((device) => LOOPBACK_INPUT_REGEX.test(String(device.label || ""))) ||
            null
          );
        }

        async function ensureInputLabelsAvailable() {
          let inputs = await listAudioInputDevices();
          const hasLabels = inputs.some((device) => String(device.label || "").trim());
          if (hasLabels || inputs.length === 0) {
            return inputs;
          }

          try {
            const probe = await navigator.mediaDevices.getUserMedia({
              audio: true,
              video: false
            });
            for (const track of probe.getTracks()) {
              try {
                track.stop();
              } catch (_) {
                // Ignore track stop errors.
              }
            }
          } catch (_) {
            // Ignore permission probe errors.
          }

          inputs = await listAudioInputDevices();
          return inputs;
        }

        async function applyTtsOutputDevice(audioEl) {
          if (!audioEl || typeof audioEl.setSinkId !== "function") {
            if (!state.ttsOutputSupportLogged) {
              addLog("tts output device routing is unavailable; using default output.");
              state.ttsOutputSupportLogged = true;
            }
            return;
          }

          let targetDeviceId = state.ttsOutputDeviceId;
          if (!targetDeviceId && state.ttsOutputDeviceLabel) {
            const outputs = await listAudioOutputDevices();
            const byLabel = findDeviceByLabel(outputs, state.ttsOutputDeviceLabel);
            if (byLabel?.deviceId) {
              targetDeviceId = byLabel.deviceId;
              state.ttsOutputDeviceId = byLabel.deviceId;
              addLog(
                `tts output selected by label: ${byLabel.label || "unknown"} [${byLabel.deviceId}]`
              );
            }
          }

          if (!targetDeviceId) {
            return;
          }

          try {
            await audioEl.setSinkId(targetDeviceId);
            if (!state.ttsOutputConfigured) {
              addLog(`tts output routed to deviceId=${targetDeviceId}`);
              state.ttsOutputConfigured = true;
            }
          } catch (err) {
            if (!state.ttsOutputConfigured) {
              addLog(
                `tts output routing failed for deviceId=${targetDeviceId}: ${err?.message || err}`
              );
              state.ttsOutputConfigured = true;
            }
          }
        }

        async function unlockAudio() {
          if (state.audioUnlocked) {
            return true;
          }

          try {
            const AudioContextCtor = window.AudioContext || window.webkitAudioContext;
            if (AudioContextCtor) {
              if (!unlockAudioContext) {
                unlockAudioContext = new AudioContextCtor();
              }

              if (unlockAudioContext.state !== "running") {
                await unlockAudioContext.resume();
              }

              const oscillator = unlockAudioContext.createOscillator();
              const gain = unlockAudioContext.createGain();
              gain.gain.value = 0.0001;
              oscillator.connect(gain);
              gain.connect(unlockAudioContext.destination);
              const startedAt = unlockAudioContext.currentTime;
              oscillator.start(startedAt);
              oscillator.stop(startedAt + 0.02);
            }

            const probe = new Audio(
              "data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEAIlYAAESsAAACABAAZGF0YQAAAAA="
            );
            probe.muted = true;
            probe.volume = 0;
            try {
              await probe.play();
              probe.pause();
            } catch (_) {
              // Ignore playback probe errors.
            }

            state.audioUnlocked = true;
            addLog("audio unlocked");
            return true;
          } catch (err) {
            addLog(`audio unlock failed: ${err?.message || err}`);
            return false;
          }
        }

        async function prepareTtsOutput() {
          try {
            await unlockAudio();
            const probe = new Audio(
              "data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEAIlYAAESsAAACABAAZGF0YQAAAAA="
            );
            probe.preload = "auto";
            probe.muted = true;
            probe.volume = 0;
            await applyTtsOutputDevice(probe);
            return true;
          } catch (err) {
            addLog(`tts output prewarm failed: ${err?.message || err}`);
            return false;
          }
        }

        function attachPlaybackStop(playback, stopHandler) {
          if (!playback || typeof stopHandler !== "function") {
            return;
          }
          playback.stopHandlers.push(stopHandler);
        }

        function notifyPlaybackQueueWaiters() {
          if (!Array.isArray(state.playback.waiters) || !state.playback.waiters.length) {
            return;
          }
          const waiters = state.playback.waiters.splice(0);
          for (const notify of waiters) {
            try {
              notify(true);
            } catch (_) {
              // Ignore waiter notification errors.
            }
          }
        }

        function waitForPlaybackQueueSignal(timeoutMs = 320) {
          if (Array.isArray(state.playback.queue) && state.playback.queue.length > 0) {
            return Promise.resolve(true);
          }
          return new Promise((resolve) => {
            let settled = false;
            const complete = (value) => {
              if (settled) {
                return;
              }
              settled = true;
              resolve(Boolean(value));
            };
            const timer = setTimeout(() => complete(false), Math.max(1, timeoutMs));
            state.playback.waiters.push(() => {
              clearTimeout(timer);
              complete(true);
            });
          });
        }

        function resolveAndClearPlaybackQueue(result = false) {
          if (!Array.isArray(state.playback.queue) || state.playback.queue.length === 0) {
            state.playback.queueDurationMs = 0;
            return;
          }
          const pending = state.playback.queue.splice(0);
          state.playback.queueDurationMs = 0;
          for (const item of pending) {
            try {
              item?.resolve?.(Boolean(result));
            } catch (_) {
              // Ignore queue item resolve errors.
            }
          }
        }

        function clearPlaybackBuffer() {
          if (state.playback.bufferTimer) {
            clearTimeout(state.playback.bufferTimer);
            state.playback.bufferTimer = null;
          }
          state.playback.bufferChunks = [];
          state.playback.bufferBytes = 0;
          state.playback.bufferSampleRate = 24000;
          state.playback.bufferChannels = 1;
        }

        function getPlaybackQueuedDurationMs() {
          return Math.max(0, Number(state.playback.queueDurationMs || 0));
        }

        function getPlaybackPlayedMs() {
          const baseMs = Math.max(0, Number(state.playback.playedMs || 0));
          const audio = state.currentAudioElement;
          if (!audio || !Number.isFinite(Number(audio.currentTime))) {
            return Math.trunc(baseMs);
          }
          return Math.max(baseMs, Math.trunc(Number(audio.currentTime) * 1000));
        }

        async function playAudioChunkWithPlayback({
          audioBase64,
          mimeType = "audio/wav",
          plannedDurationMs = 0,
          playback
        } = {}) {
          const source = `data:${mimeType};base64,${audioBase64}`;
          const audio = new Audio(source);
          audio.preload = "auto";
          audio.volume = effectiveTtsVolume();
          await applyTtsOutputDevice(audio);
          state.currentAudioElement = audio;

          return new Promise((resolve) => {
            let resolved = false;
            const startedAt = Date.now();
            const done = (ok, errorMessage = "") => {
              if (resolved) {
                return;
              }
              resolved = true;
              const elapsedMs = Math.max(0, Date.now() - startedAt);
              const playedMs = ok
                ? Math.max(0, Math.trunc(Number(plannedDurationMs || elapsedMs)))
                : Math.max(
                    0,
                    Math.trunc(
                      Number.isFinite(Number(audio.currentTime))
                        ? Number(audio.currentTime) * 1000
                        : Math.min(elapsedMs, Number(plannedDurationMs || elapsedMs))
                    )
                  );
              if (state.currentAudioElement === audio) {
                state.currentAudioElement = null;
              }
              resolve({
                ok: Boolean(ok),
                errorMessage,
                playedMs
              });
            };

            const handleStop = (reason = "playback interrupted") => {
              try {
                audio.pause();
              } catch (_) {
                // Ignore pause errors.
              }
              done(false, String(reason || "playback interrupted"));
            };

            attachPlaybackStop(playback, handleStop);

            audio.onended = () => {
              done(true, "");
            };

            audio.onerror = () => {
              done(false, "audio decode/playback failed");
            };

            const started = audio.play();
            if (started && typeof started.catch === "function") {
              started.catch((err) => {
                done(false, err?.message || "audio.play() rejected");
              });
            }
          });
        }

        async function withSpeechLock(runPlayback) {
          const playback = {
            stopped: false,
            stopHandlers: [],
            startedChunks: 0
          };

          state.speaking = true;
          state.playback.playedMs = 0;
          const startGateMs = Math.min(120, Math.max(0, Number(state.silenceMs || 0)));
          state.captureGateUntilMs = Date.now() + startGateMs;
          setSpeechState("speaking");
          state.playback.current = playback;
          addLog(`tts playback start (gateMs=${startGateMs})`);
          emitBridgeEvent({
            source: "bridge-tts",
            type: "tts.playback.start",
            gateMs: startGateMs
          });

          try {
            await unlockAudio();
            await runPlayback(playback);
          } finally {
            if (state.playback.current === playback) {
              state.playback.current = null;
            }
            const endGateMs = playback.stopped
              ? Math.min(80, Math.max(0, Number(state.silenceMs || 0)))
              : Math.max(0, Number(state.silenceMs || 0));
            state.captureGateUntilMs = Date.now() + endGateMs;
            state.speaking = false;
            setSpeechState(playback.stopped ? "interrupted" : "idle");
            addLog(
              `tts playback end (state=${playback.stopped ? "interrupted" : "completed"}, gateMs=${endGateMs})`
            );
            emitBridgeEvent({
              source: "bridge-tts",
              type: "tts.playback.end",
              gateMs: endGateMs,
              interrupted: playback.stopped
            });
          }
        }

        async function ensureStreamingPlaybackLoop() {
          if (state.playback.loopPromise) {
            return state.playback.loopPromise;
          }

          state.playback.loopPromise = withSpeechLock(async (playback) => {
            while (!playback.stopped) {
              if (
                playback.startedChunks === 0 &&
                Array.isArray(state.playback.queue) &&
                state.playback.queue.length > 0
              ) {
                const minJitterMs = 90;
                const minJitterChunks = 3;
                const startedWaitAt = Date.now();
                while (!playback.stopped) {
                  const queuedChunks = state.playback.queue.length;
                  const queuedMs = getPlaybackQueuedDurationMs();
                  if (queuedChunks >= minJitterChunks || queuedMs >= minJitterMs) {
                    break;
                  }
                  const elapsed = Date.now() - startedWaitAt;
                  if (elapsed >= 180) {
                    break;
                  }
                  const hasMore = await waitForPlaybackQueueSignal(60);
                  if (!hasMore) {
                    break;
                  }
                }
              }

              if (!Array.isArray(state.playback.queue) || state.playback.queue.length === 0) {
                const hasMore = await waitForPlaybackQueueSignal(650);
                if (!hasMore || playback.stopped) {
                  break;
                }
              }

              const nextItem = state.playback.queue.shift();
              if (!nextItem) {
                continue;
              }
              state.playback.queueDurationMs = Math.max(
                0,
                getPlaybackQueuedDurationMs() -
                  Math.max(1, Number(nextItem.durationMs || 0))
              );

              const result = await playAudioChunkWithPlayback({
                audioBase64: nextItem.audioBase64,
                mimeType: nextItem.mimeType,
                plannedDurationMs: nextItem.durationMs,
                playback
              });
              playback.startedChunks += 1;
              state.playback.playedMs = Math.max(
                0,
                Number(state.playback.playedMs || 0) +
                  Math.max(0, Number(result?.playedMs || 0))
              );
              nextItem.resolve(result.ok);

              if (!result.ok && result.errorMessage && result.errorMessage !== "playback interrupted") {
                addLog(`audio play failed: ${result.errorMessage}`);
              }
            }

            if (playback.stopped) {
              resolveAndClearPlaybackQueue(false);
            }
          })
            .catch((err) => {
              addLog(`playback loop failed: ${err?.message || err}`);
              resolveAndClearPlaybackQueue(false);
            })
            .finally(() => {
              state.playback.loopPromise = null;
              notifyPlaybackQueueWaiters();
            });

          return state.playback.loopPromise;
        }

        function enqueuePlaybackChunk({
          audioBase64,
          mimeType = "audio/wav",
          durationMs = 0
        } = {}) {
          const normalizedAudio = String(audioBase64 || "").trim();
          if (!normalizedAudio) {
            return false;
          }

          const normalizedDurationMs = Math.max(
            1,
            Number(durationMs) ||
              estimateChunkDurationMs({
                bytesLength: Math.max(0, Math.floor((normalizedAudio.length * 3) / 4)),
                sampleRateHz: state.playback.bufferSampleRate,
                channels: state.playback.bufferChannels
              })
          );

          return new Promise((resolve) => {
            state.playback.queue.push({
              audioBase64: normalizedAudio,
              mimeType,
              durationMs: normalizedDurationMs,
              resolve
            });
            state.playback.queueDurationMs = getPlaybackQueuedDurationMs() + normalizedDurationMs;
            notifyPlaybackQueueWaiters();
            void ensureStreamingPlaybackLoop();
          });
        }

        function estimateChunkDurationMs({ bytesLength = 0, sampleRateHz = 24000, channels = 1 } = {}) {
          const samples = Math.floor(Math.max(0, Number(bytesLength) || 0) / 2 / Math.max(1, Number(channels) || 1));
          if (!samples) {
            return 0;
          }
          return Math.max(1, Math.round((samples / Math.max(8000, Number(sampleRateHz) || 24000)) * 1000));
        }

        async function flushPlaybackBuffer({ force = false } = {}) {
          const chunks = state.playback.bufferChunks;
          if (!Array.isArray(chunks) || chunks.length === 0) {
            clearPlaybackBuffer();
            return;
          }

          const sampleRate = Math.max(8000, Number(state.playback.bufferSampleRate) || 24000);
          const channels = Math.max(1, Number(state.playback.bufferChannels) || 1);
          const durationMs = estimateChunkDurationMs({
            bytesLength: state.playback.bufferBytes,
            sampleRateHz: sampleRate,
            channels
          });

          if (!force && durationMs < 320) {
            return;
          }

          const totalBytes = chunks.reduce((sum, chunk) => sum + (chunk?.byteLength || 0), 0);
          if (!totalBytes) {
            clearPlaybackBuffer();
            return;
          }

          const merged = new Uint8Array(totalBytes);
          let offset = 0;
          for (const chunk of chunks) {
            if (!(chunk instanceof Uint8Array) || !chunk.byteLength) {
              continue;
            }
            merged.set(chunk, offset);
            offset += chunk.byteLength;
          }

          clearPlaybackBuffer();

          if (!offset) {
            return;
          }

          const wavBase64 = pcm16BytesToWavBase64(merged.subarray(0, offset), sampleRate, channels);
          if (!wavBase64) {
            return;
          }

          await enqueuePlaybackChunk({
            audioBase64: wavBase64,
            mimeType: "audio/wav",
            durationMs: estimateChunkDurationMs({
              bytesLength: offset,
              sampleRateHz: sampleRate,
              channels
            })
          });
        }

        function bufferPcmOutputChunk({ bytes, sampleRate = 24000, channels = 1 } = {}) {
          if (!(bytes instanceof Uint8Array) || !bytes.byteLength) {
            return;
          }

          state.playback.bufferChunks.push(bytes);
          state.playback.bufferBytes += bytes.byteLength;
          state.playback.bufferSampleRate = Math.max(8000, Number(sampleRate) || 24000);
          state.playback.bufferChannels = Math.max(1, Number(channels) || 1);

          const durationMs = estimateChunkDurationMs({
            bytesLength: state.playback.bufferBytes,
            sampleRateHz: state.playback.bufferSampleRate,
            channels: state.playback.bufferChannels
          });

          if (durationMs >= 420) {
            void flushPlaybackBuffer({ force: true });
            return;
          }

          if (!state.playback.bufferTimer) {
            state.playback.bufferTimer = setTimeout(() => {
              state.playback.bufferTimer = null;
              void flushPlaybackBuffer({ force: true });
            }, 120);
          }
        }

        function stopSpeaking(options = {}) {
          const flush = options?.flush !== false;
          const resumeGateMs = Number.isFinite(Number(options?.resumeGateMs))
            ? Math.max(0, Math.trunc(Number(options.resumeGateMs)))
            : Math.min(80, Math.max(0, Number(state.silenceMs || 0)));

          clearPlaybackBuffer();

          const queuedCount = Array.isArray(state.playback.queue)
            ? state.playback.queue.length
            : 0;
          if (queuedCount > 0) {
            resolveAndClearPlaybackQueue(false);
            notifyPlaybackQueueWaiters();
          }

          const playback = state.playback.current;
          if (!playback || playback.stopped) {
            if (queuedCount > 0) {
              addLog(`stopSpeaking cleared queued playback (${queuedCount} chunks)`);
            }
            state.playback.queueDurationMs = 0;
            if (!state.speaking) {
              state.playback.playedMs = 0;
            }
            if (flush) {
              state.captureGateUntilMs = Date.now() + resumeGateMs;
            }
            return queuedCount > 0;
          }

          playback.stopped = true;
          for (const stopHandler of playback.stopHandlers) {
            try {
              stopHandler("manual-stop");
            } catch (_) {
              // Ignore stop handler errors.
            }
          }
          playback.stopHandlers = [];

          if (flush) {
            state.captureGateUntilMs = Date.now() + resumeGateMs;
          }
          state.playback.queueDurationMs = 0;

          addLog("stopSpeaking applied: active playback interrupted");
          return true;
        }

        function setTtsDucking(options = {}) {
          const active = typeof options.active === "boolean" ? options.active : Boolean(options);
          if (Number.isFinite(options.level)) {
            state.ttsDuckLevel = Math.max(0, Math.min(1, Number(options.level)));
          }
          state.ttsDuckActive = active;
          applyCurrentAudioVolume();
          addLog(
            `tts ducking ${active ? "enabled" : "disabled"} (level=${effectiveTtsVolume().toFixed(2)})`
          );
          return true;
        }

        function normalizeCoreWsUrl(options = {}) {
          const explicit = String(options.wsUrl || "").trim();
          if (explicit) {
            return explicit;
          }

          const host = String(options.controlApiHost || window.location.hostname || "127.0.0.1")
            .trim() || "127.0.0.1";
          const port = Math.max(
            1,
            Math.min(65535, Math.trunc(Number(options.controlApiPort || 3200)))
          );
          const path = String(options.wsPath || "/ws/voice").trim() || "/ws/voice";
          const protocol =
            String(options.wsProtocol || "").trim() ||
            (window.location.protocol === "https:" ? "wss" : "ws");
          const url = new URL(`${protocol}://${host}:${port}${path}`);

          const token = String(options.controlApiToken || "").trim();
          if (token) {
            url.searchParams.set("token", token);
          }
          return url.toString();
        }

        function sendCoreControlEvent(type, payload = {}) {
          const core = state.core;
          const ws = core.ws;
          if (!ws || ws.readyState !== WebSocket.OPEN) {
            return false;
          }
          try {
            ws.send(
              JSON.stringify(
                buildVoiceCoreEnvelope({
                  type,
                  sessionId: core.sessionId || "",
                  payload
                })
              )
            );
            return true;
          } catch (_) {
            return false;
          }
        }

        function handleCoreWsControlEnvelope(envelope = {}) {
          const type = String(envelope?.type || "").trim().toLowerCase();
          if (!type) {
            return;
          }
          const payload =
            envelope?.payload && typeof envelope.payload === "object" ? envelope.payload : {};

          if (type === "welcome") {
            addLog("core event: welcome");
            return;
          }

          if (type === "session.started") {
            state.core.sessionId =
              String(payload.session_id || envelope.session_id || "").trim() ||
              state.core.sessionId;
            setRecognitionState("voice-core");
            addLog(
              `core session started (id=${state.core.sessionId || "unknown"}, model=${String(
                payload?.model || "unknown"
              )})`
            );
            return;
          }

          if (type === "session.state") {
            const sessionState = String(payload?.state || "unknown").trim().toLowerCase();
            addLog(`core session state: ${sessionState || "unknown"}`);
            return;
          }

          if (type === "stt.partial") {
            const text = String(payload?.text || "").trim();
            if (!text) {
              return;
            }
            emitBridgeEvent({
              source: "openai-realtime",
              type: "transcript.partial",
              text,
              turnId: String(payload?.turn_id || "").trim() || undefined
            });
            return;
          }

          if (type === "stt.final") {
            const text = String(payload?.text || "").trim();
            if (!text) {
              return;
            }
            const turnId = String(payload?.turn_id || "").trim() || undefined;
            emitBridgeEvent({
              source: "openai-realtime",
              type: "transcript.final",
              text,
              turnId,
              isFinal: true
            });
            emitBridgeEvent({
              source: "openai-realtime",
              type: "turn.final",
              text,
              turnId,
              isFinal: true
            });
            return;
          }

          if (type === "assistant.state") {
            const assistantState = String(payload?.state || "")
              .trim()
              .toLowerCase();
            if (!assistantState) {
              return;
            }
            const responseId = String(payload?.response_id || "").trim() || undefined;
            if (assistantState === "speaking") {
              state.playback.playedMs = 0;
              emitBridgeEvent({
                source: "openai-realtime",
                type: "assistant.response.started",
                responseId
              });
            } else if (assistantState === "done" || assistantState === "interrupted") {
              emitBridgeEvent({
                source: "openai-realtime",
                type: "assistant.response.done",
                responseId,
                status: assistantState
              });
            }
            return;
          }

          if (type === "assistant.text.delta") {
            const text = String(payload?.text || "").trim();
            if (!text) {
              return;
            }
            emitBridgeEvent({
              source: "openai-realtime",
              type: "assistant.text.partial",
              responseId: String(payload?.response_id || "").trim() || undefined,
              text
            });
            return;
          }

          if (type === "assistant.text.final") {
            const text = String(payload?.text || "").trim();
            if (!text) {
              return;
            }
            emitBridgeEvent({
              source: "openai-realtime",
              type: "assistant.text.final",
              responseId: String(payload?.response_id || "").trim() || undefined,
              text,
              isFinal: true
            });
            return;
          }

          if (type === "audio.committed") {
            addLog("core input committed");
            return;
          }

          if (type === "audio.clear") {
            stopSpeaking({
              flush: true,
              resumeGateMs: 0
            });
            emitBridgeEvent({
              source: "openai-realtime",
              type: "assistant.response.done",
              status: "interrupted"
            });
            addLog(`core audio cleared (${String(payload?.reason || "audio.clear")})`);
            return;
          }

          if (type === "turn.eot") {
            addLog(
              `core turn.eot (reason=${String(payload?.reason || "unknown")}, delayMs=${Number(
                payload?.delay_ms || 0
              )})`
            );
            return;
          }

          if (type === "metrics.tick") {
            const firstAudioMs = Number(payload?.first_audio_ms || 0);
            if (Number.isFinite(firstAudioMs) && firstAudioMs > 0) {
              addLog(`core metrics first_audio_ms=${Math.round(firstAudioMs)}`);
            }
            return;
          }

          if (type === "warning") {
            addLog(
              `core warning: ${String(payload?.message || payload?.code || "warning")}`
            );
            return;
          }

          if (type === "error") {
            const message = String(payload?.message || "Voice core error.").trim();
            addLog(`core error: ${message}`);
            emitBridgeEvent({
              source: "openai-realtime",
              type: "realtime.error",
              reason: message
            });
            return;
          }

          if (type === "pong") {
            addLog("core pong");
          }
        }

        function handleCoreWsBinaryFrame(raw) {
          let frame;
          try {
            frame = decodeVoiceBinaryAudioFrame(raw);
          } catch (decodeErr) {
            addLog(`core binary decode failed: ${decodeErr?.message || decodeErr}`);
            return;
          }

          if (frame.kindCode !== VOICE_AUDIO_KIND_OUTPUT || frame.bytes.byteLength === 0) {
            return;
          }

          const now = Date.now();
          if (now - Number(state.core.lastAudioChunkLogAtMs || 0) > 1200) {
            state.core.lastAudioChunkLogAtMs = now;
            const approxMs = Math.round(
              (frame.bytes.byteLength / 2 / Math.max(8000, Number(frame.sampleRateHz || 24000))) *
                1000
            );
            addLog(`assistant audio chunk (format=pcm16, ~${approxMs}ms)`);
          }

          bufferPcmOutputChunk({
            bytes: frame.bytes,
            sampleRate: frame.sampleRateHz,
            channels: frame.channels
          });
        }

        async function resolveCoreInputStream(options = {}) {
          const requestedDeviceId = String(options.inputDeviceId || "").trim();
          const requestedDeviceLabel = String(options.inputDeviceLabel || "").trim();
          const strictRequestedInput = Boolean(requestedDeviceId || requestedDeviceLabel);

          const audioConstraints = {
            echoCancellation: false,
            noiseSuppression: false,
            autoGainControl: false,
            channelCount: 1
          };

          const devices = await ensureInputLabelsAvailable();
          if (devices.length > 0) {
            addLog(
              `core audio inputs: ${devices
                .map((device, index) => formatDeviceLabel(device, index))
                .join(" | ")}`
            );
          }

          let selectedDeviceId = requestedDeviceId;
          let selectedDeviceLabel = "";

          if (selectedDeviceId) {
            const byId =
              devices.find(
                (device) => String(device?.deviceId || "").trim() === selectedDeviceId
              ) || null;
            if (byId?.label) {
              selectedDeviceLabel = byId.label;
            } else if (strictRequestedInput) {
              throw new Error(`Core input deviceId is not available: ${selectedDeviceId}`);
            }
          }

          if (!selectedDeviceId && requestedDeviceLabel) {
            const byLabel = findDeviceByLabel(devices, requestedDeviceLabel);
            if (byLabel?.deviceId) {
              selectedDeviceId = byLabel.deviceId;
              selectedDeviceLabel = byLabel.label || "";
            } else {
              throw new Error(`Core input device label not found: \"${requestedDeviceLabel}\"`);
            }
          } else if (!selectedDeviceId) {
            const preferLoopback = options.inputPreferLoopback !== false;
            if (preferLoopback) {
              const loopback = findLoopbackDevice(devices);
              if (loopback?.deviceId) {
                selectedDeviceId = loopback.deviceId;
                selectedDeviceLabel = loopback.label || "";
              }
            }
          }

          if (selectedDeviceId) {
            audioConstraints.deviceId = { exact: selectedDeviceId };
          }

          const requestStream = async (constraints) =>
            navigator.mediaDevices.getUserMedia({
              audio: constraints,
              video: false
            });

          let stream;
          try {
            stream = await requestStream(audioConstraints);
          } catch (err) {
            const name = String(err?.name || "");
            const overconstrained =
              name === "OverconstrainedError" || name === "ConstraintNotSatisfiedError";
            if (!overconstrained) {
              throw err;
            }

            const relaxedWithDevice = selectedDeviceId
              ? { deviceId: { exact: selectedDeviceId } }
              : true;
            try {
              stream = await requestStream(relaxedWithDevice);
            } catch (relaxedErr) {
              if (strictRequestedInput) {
                throw new Error(
                  `Core input device became unavailable: ${relaxedErr?.message || relaxedErr}`
                );
              }
              stream = await requestStream(true);
              selectedDeviceId = "";
              selectedDeviceLabel = "";
            }
          }

          addLog(
            `core selected input: ${selectedDeviceLabel || "default input"} [${
              selectedDeviceId || "default"
            }]`
          );

          return {
            stream,
            selectedDeviceId,
            selectedDeviceLabel
          };
        }

        function cleanupCoreCapture() {
          const core = state.core;
          const stream = core.localStream;
          const audioContext = core.audioContext;
          const sourceNode = core.sourceNode;
          const processorNode = core.processorNode;
          const sinkNode = core.sinkNode;

          core.localStream = null;
          core.audioContext = null;
          core.sourceNode = null;
          core.processorNode = null;
          core.sinkNode = null;
          core.sampleRate = 48000;
          core.speechActive = false;
          core.speechStartedAtMs = 0;
          core.lastSpeechAtMs = 0;
          core.pendingInput = false;

          if (processorNode) {
            try {
              processorNode.onaudioprocess = null;
              processorNode.disconnect();
            } catch (_) {
              // Ignore disconnect races.
            }
          }
          if (sourceNode) {
            try {
              sourceNode.disconnect();
            } catch (_) {
              // Ignore disconnect races.
            }
          }
          if (sinkNode) {
            try {
              sinkNode.disconnect();
            } catch (_) {
              // Ignore disconnect races.
            }
          }
          if (audioContext) {
            Promise.resolve(audioContext.close()).catch(() => {});
          }
          if (stream) {
            for (const track of stream.getTracks()) {
              try {
                track.stop();
              } catch (_) {
                // Ignore stop races.
              }
            }
          }
        }

        async function stopCoreWs(options = {}) {
          const core = state.core;
          const ws = core.ws;

          core.starting = false;
          core.active = false;

          if (ws && ws.readyState === WebSocket.OPEN) {
            if (core.pendingInput && options?.commit !== false) {
              sendCoreControlEvent("audio.commit", {
                reason: String(options?.reason || "bridge_stop").trim() || "bridge_stop",
                force_response: false
              });
            }
            sendCoreControlEvent("session.stop", {
              reason: String(options?.reason || "bridge_stop").trim() || "bridge_stop"
            });
          }

          if (ws) {
            try {
              ws.onopen = null;
              ws.onclose = null;
              ws.onmessage = null;
              ws.onerror = null;
              ws.close();
            } catch (_) {
              // Ignore close races.
            }
          }

          core.ws = null;
          core.sessionId = "";

          cleanupCoreCapture();
          stopSpeaking({
            flush: true,
            resumeGateMs: 0
          });

          setRecognitionState("stopped");
          addLog(`core stopped (reason=${String(options?.reason || "stop")})`);
          return true;
        }

        async function startCoreWs(options = {}) {
          const core = state.core;
          if (core.active || core.starting) {
            return false;
          }

          core.starting = true;
          core.bargeInMinMs = Number.isFinite(Number(options.bargeInMinMs))
            ? Math.max(80, Math.min(5000, Math.trunc(Number(options.bargeInMinMs))))
            : core.bargeInMinMs;

          try {
            await stopCoreWs({ reason: "restart-before-start", commit: false }).catch(() => {});
            await unlockAudio();

            const wsUrl = normalizeCoreWsUrl(options);
            const socket = new WebSocket(wsUrl, VOICE_CORE_PROTOCOL);
            socket.binaryType = "arraybuffer";

            await new Promise((resolve, reject) => {
              let settled = false;
              const finish = (callback) => {
                if (settled) {
                  return;
                }
                settled = true;
                clearTimeout(timer);
                socket.removeEventListener("open", onOpen);
                socket.removeEventListener("error", onError);
                callback();
              };

              const onOpen = () => finish(resolve);
              const onError = () =>
                finish(() => reject(new Error("voice-core websocket connect failed")));

              const timer = setTimeout(() => {
                finish(() => reject(new Error("voice-core websocket connect timed out")));
              }, Math.max(1000, Math.min(30000, Math.trunc(Number(options.connectTimeoutMs || 8000)))));

              socket.addEventListener("open", onOpen);
              socket.addEventListener("error", onError);
            });

            const { stream } = await resolveCoreInputStream(options);

            const AudioContextCtor = window.AudioContext || window.webkitAudioContext;
            const audioContext = new AudioContextCtor();
            if (audioContext.state !== "running") {
              await audioContext.resume();
            }

            const sourceNode = audioContext.createMediaStreamSource(stream);
            const processorNode = audioContext.createScriptProcessor(2048, 1, 1);
            const sinkNode = audioContext.createGain();
            sinkNode.gain.value = 0;

            core.inputSeq = 0;
            core.localStream = stream;
            core.audioContext = audioContext;
            core.sourceNode = sourceNode;
            core.processorNode = processorNode;
            core.sinkNode = sinkNode;
            core.sampleRate = Math.max(
              8000,
              Math.min(96000, Math.trunc(Number(audioContext.sampleRate) || 48000))
            );
            core.pendingInput = false;
            core.lastAudioChunkLogAtMs = 0;

            processorNode.onaudioprocess = (audioEvent) => {
              try {
                if (!core.active || !core.ws || core.ws.readyState !== WebSocket.OPEN) {
                  return;
                }
                if (core.ws.bufferedAmount > 2 * 1024 * 1024) {
                  return;
                }
                if (Date.now() < Number(state.captureGateUntilMs || 0)) {
                  return;
                }

                const input = audioEvent?.inputBuffer?.getChannelData(0);
                if (!input || input.length === 0) {
                  return;
                }

                const peak = computePeak(input);
                const localVadThreshold = Math.max(
                  0.01,
                  Number(options.localVadThreshold || 0.018)
                );
                const now = Date.now();
                if (peak >= localVadThreshold) {
                  core.lastSpeechAtMs = now;
                  if (!core.speechActive) {
                    core.speechActive = true;
                    core.speechStartedAtMs = now;
                    emitBridgeEvent({
                      source: "openai-realtime",
                      type: "vad.start",
                      reason: "local-vad",
                      peak
                    });
                  }
                } else if (
                  core.speechActive &&
                  now - Number(core.lastSpeechAtMs || 0) > 260
                ) {
                  const speechMs = Math.max(0, now - Number(core.speechStartedAtMs || now));
                  if (speechMs >= Math.max(80, Number(core.bargeInMinMs || 220))) {
                    emitBridgeEvent({
                      source: "openai-realtime",
                      type: "vad.confirmed",
                      reason: "local-vad",
                      speechMs,
                      peak
                    });
                  }
                  core.speechActive = false;
                  core.speechStartedAtMs = 0;
                  emitBridgeEvent({
                    source: "openai-realtime",
                    type: "vad.stop",
                    reason: "local-vad"
                  });
                }

                const normalized = downsampleFloat32Buffer(input, audioContext.sampleRate, 24000);
                if (!normalized.length) {
                  return;
                }

                const pcmBytes = float32ToPcm16Bytes(normalized);
                if (!pcmBytes.length) {
                  return;
                }

                core.inputSeq += 1;
                const binaryFrame = encodeVoiceInputBinaryAudioFrame({
                  seq: core.inputSeq,
                  sampleRateHz: 24000,
                  channels: 1,
                  pcmBytes
                });
                if (!binaryFrame) {
                  return;
                }

                core.ws.send(binaryFrame);
                core.pendingInput = true;
              } catch (_) {
                // Ignore per-frame processing errors.
              }
            };

            sourceNode.connect(processorNode);
            processorNode.connect(sinkNode);
            sinkNode.connect(audioContext.destination);

            core.ws = socket;
            core.active = true;
            core.starting = false;

            socket.onmessage = async (messageEvent) => {
              const data = messageEvent?.data;
              if (data instanceof ArrayBuffer) {
                handleCoreWsBinaryFrame(data);
                return;
              }
              if (typeof Blob !== "undefined" && data instanceof Blob) {
                try {
                  const raw = await data.arrayBuffer();
                  handleCoreWsBinaryFrame(raw);
                } catch (_) {
                  // Ignore blob decode errors.
                }
                return;
              }
              try {
                const parsed = JSON.parse(String(data || "{}"));
                handleCoreWsControlEnvelope(parsed);
              } catch (_) {
                // Ignore malformed control payload.
              }
            };

            socket.onclose = (closeEvent) => {
              const code = Number(closeEvent?.code || 0);
              const reason = String(closeEvent?.reason || "").trim();
              const wasActive = core.active;

              core.active = false;
              core.starting = false;
              core.ws = null;

              cleanupCoreCapture();
              clearPlaybackBuffer();

              setRecognitionState("disconnected", true);
              addLog(
                `core websocket closed (code=${code}${reason ? `, reason=${reason}` : ""})`
              );

              if (wasActive) {
                emitBridgeEvent({
                  source: "openai-realtime",
                  type: "realtime.error",
                  reason: "voice core websocket disconnected"
                });
              }
            };

            socket.onerror = () => {
              addLog("core websocket transport error");
              emitBridgeEvent({
                source: "openai-realtime",
                type: "realtime.error",
                reason: "voice core websocket transport error"
              });
            };

            const started = sendCoreControlEvent("session.start", {
              client: {
                kind: "meet-bridge",
                actor: "bot",
                protocol: VOICE_CORE_PROTOCOL
              },
              language: String(options.language || state.language || "en-US"),
              systemPrompt: String(options.instructions || "").trim(),
              openaiTemperature: Number.isFinite(Number(options.temperature))
                ? Number(options.temperature)
                : 0.8,
              openaiRealtimeModel: String(
                options.model || "gpt-4o-mini-realtime-preview-2024-12-17"
              ).trim(),
              openaiRealtimeInputTranscriptionModel: String(
                options.inputTranscriptionModel || "gpt-4o-mini-transcribe"
              ).trim(),
              openaiTtsVoice: String(options.voice || "alloy").trim() || "alloy",
              openaiRealtimeTurnDetection: String(
                options.turnDetection || "semantic_vad"
              ).trim().toLowerCase(),
              openaiRealtimeTurnEagerness: String(
                options.turnDetectionEagerness || "auto"
              ).trim().toLowerCase(),
              openaiRealtimeVadThreshold: Number.isFinite(Number(options.vadThreshold))
                ? Number(options.vadThreshold)
                : 0.45,
              openaiRealtimeVadSilenceMs: Number.isFinite(Number(options.vadSilenceMs))
                ? Math.max(120, Math.trunc(Number(options.vadSilenceMs)))
                : 280,
              openaiRealtimeVadPrefixPaddingMs: Number.isFinite(Number(options.vadPrefixPaddingMs))
                ? Math.max(0, Math.trunc(Number(options.vadPrefixPaddingMs)))
                : 180,
              openaiRealtimeInterruptResponseOnTurn: options.interruptResponseOnTurn !== false,
              openaiRealtimeUpstreamTurnDetectionEnabled: false
            });
            if (!started) {
              throw new Error("failed to send session.start to voice-core");
            }

            setRecognitionState("voice-core");
            addLog(
              `core started (model=${String(options.model || "unknown")}, ws=${wsUrl.replace(
                /\?.*$/,
                ""
              )})`
            );
            return true;
          } catch (err) {
            await stopCoreWs({ reason: "start-failed", commit: false }).catch(() => {});
            const message = String(err?.message || err || "core start failed");
            addLog(`core start failed: ${message}`);
            emitBridgeEvent({
              source: "openai-realtime",
              type: "realtime.error",
              reason: message
            });
            setRecognitionState("error", true);
            return false;
          } finally {
            core.starting = false;
          }
        }

        async function coreInterrupt(options = {}) {
          if (!state.core.active || !state.core.ws || state.core.ws.readyState !== WebSocket.OPEN) {
            return false;
          }
          const reason = String(options?.reason || "bridge_interrupt").trim() || "bridge_interrupt";
          const playedMs = Math.max(
            0,
            Math.trunc(Number(options?.playedMs || getPlaybackPlayedMs()) || 0)
          );
          const sent = sendCoreControlEvent("assistant.interrupt", {
            reason,
            played_ms: playedMs
          });
          stopSpeaking({
            flush: true,
            resumeGateMs: 0
          });
          addLog(`core interrupt sent (${reason}, playedMs=${playedMs})`);
          return Boolean(sent);
        }

        async function coreCreateTextTurn(payload = {}) {
          if (!state.core.active || !state.core.ws || state.core.ws.readyState !== WebSocket.OPEN) {
            return false;
          }
          const text = String(payload?.text || "").trim();
          if (!text) {
            return false;
          }
          const role =
            String(payload?.role || "user").trim().toLowerCase() === "system" ? "system" : "user";
          const createResponse = payload?.createResponse !== false;
          const sent = sendCoreControlEvent("text.input", {
            role,
            text,
            create_response: createResponse
          });
          if (sent) {
            addLog(`text.input sent (role=${role}, chars=${text.length}, createResponse=${createResponse})`);
          }
          return Boolean(sent);
        }

        async function coreAppendSystemContext(note = "") {
          const text = String(note || "").trim();
          if (!text) {
            return false;
          }
          return coreCreateTextTurn({
            role: "system",
            text,
            createResponse: false
          });
        }

        function configure(options = {}) {
          if (typeof options.language === "string" && options.language) {
            state.language = options.language;
          }
          if (Number.isFinite(options.silenceMs)) {
            state.silenceMs = options.silenceMs;
          }
          if (Number.isFinite(options.ttsDuckLevel)) {
            state.ttsDuckLevel = Math.max(0, Math.min(1, Number(options.ttsDuckLevel)));
            applyCurrentAudioVolume();
          }
          if (
            typeof options.ttsOutputDeviceId === "string" &&
            options.ttsOutputDeviceId.trim()
          ) {
            state.ttsOutputDeviceId = options.ttsOutputDeviceId.trim();
            state.ttsOutputConfigured = false;
          }
          if (
            typeof options.ttsOutputDeviceLabel === "string" &&
            options.ttsOutputDeviceLabel.trim()
          ) {
            state.ttsOutputDeviceLabel = options.ttsOutputDeviceLabel.trim();
            state.ttsOutputConfigured = false;
          }
        }

        parseQuery();
        configure({
          language: state.language,
          silenceMs: state.silenceMs,
          ttsDuckLevel: state.ttsDuckLevel,
          ttsOutputDeviceId: state.ttsOutputDeviceId,
          ttsOutputDeviceLabel: state.ttsOutputDeviceLabel
        });

        window.botBridge = {
          startCoreWs,
          stopCoreWs,
          coreInterrupt,
          coreCreateTextTurn,
          coreAppendSystemContext,
          stopSpeaking,
          setTtsDucking,
          unlockAudio,
          prepareTtsOutput,
          configure
        };

        addLog("bridge loaded (voice.core.v1 transport)");
        setRecognitionState("ready");
      })();
    </script>
  </body>
</html>
